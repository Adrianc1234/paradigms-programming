{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring data using Pandas\n",
    "\n",
    "\n",
    "Our first task in this week's lesson is to learn how to read and explore data files using Pandas. \n",
    "\n",
    "While exploring the weather data, we will get familiar with Pandas data structures: *Series* and *DataFrame*. **Pandas DataFrame** (a 2-dimensional data structure) is used for storing and mainpulating table-like data (data with rows and columns) in Python. You can think of Pandas DataFrame as an attribute table (an excel-like spreadsheet, but much better!). **Pandas Series** (a 1-dimensional data structure) is used for storing and manipulating an sequence of values. Pandas Series is kind of like a list, but more clever. One row or one column in a Pandas DataFrame is actually a Pandas Series. For a comprehensive overview of pandas data structures, you can have a look at Wes MacKinney's book **Python for Data Analysis (2nd Edition, 2017)** and [Pandas online documentation about data structures](https://pandas.pydata.org/pandas-docs/stable/dsintro.html).\n",
    "\n",
    "Reading data files using Pandas will make life a bit easier compared to the traditional Python way of reading data files. If you're curious about that, you can check out some of the [lesson materials from previous years about reading data \n",
    "in the Pythonic way](https://geo-python.github.io/2018/2017/lessons/L5/reading-data-from-file.html). \n",
    "\n",
    "## Preparations for this lesson (working environment and input data)\n",
    "\n",
    "\n",
    "1. Start a jupyter lab instance (using the links at the top of this page) and open this lesson in an interactive mode.\n",
    "2. Have a look at the input data which is a text file containing weather observations from Kumpula\n",
    "\n",
    "    - The data file name is [Kumpula-June-2016-w-metadata.txt](Kumpula-June-2016-w-metadata.txt)\n",
    "    - The file is available in the binder and CSC notebook instances, under L5 folder \n",
    "    - The data file contains observed daily mean, minimum, and maximum temperatures from June 2016 recorded from the Kumpula weather observation station in Helsinki.\n",
    "    - The data has been derived from a data file of daily temperature measurments downloaded from the [US National Oceanographic and Atmospheric Administration's National Centers for Environmental Information climate database](https://www.ncdc.noaa.gov/cdo-web/).\n",
    "    - There are something like 30 lines of data in the data file.\n",
    "\n",
    "\n",
    "## Reading a data file with Pandas\n",
    "\n",
    "\n",
    "Now we're ready to read in our temperature data file. **First, we need to import the Pandas module.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, Pandas is ready to use now. \n",
    "\n",
    "Notice we imported the Pandas module with the name `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we'll read the file data into a variable called `dataFrame`.** Using the `pandas.read_csv` -function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using pandas\n",
    "dataFrame = pd.read_csv('Kumpula-June-2016-w-metadata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_csv()` is a general function for reading data files separated by commas, spaces, or other common separators. For a full list of parameters for this function, please refer to [pandas documentation for pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "Here we use the function simply by giving the filename as an input parameter. If all goes as planned, you should now have a new variable defined as `dataFrame` in memory that contains the data file's contents. You can check the the contents of this variable by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       # Data file contents: Daily temperatures (mean            min  \\\n",
      "0                 #                     for June 1-30           2016   \n",
      "1   # Data source: https://www.ncdc.noaa.gov/cdo-w...            NaN   \n",
      "2   # Data processing: Extracted temperatures from...   converted to   \n",
      "3           #                  comma-separated format            NaN   \n",
      "4                                                   #            NaN   \n",
      "5                          # David Whipp - 02.10.2017            NaN   \n",
      "6                                            YEARMODA           TEMP   \n",
      "7                                            20160601           65.5   \n",
      "8                                            20160602           65.8   \n",
      "9                                            20160603           68.4   \n",
      "10                                           20160604           57.5   \n",
      "11                                           20160605           51.4   \n",
      "12                                           20160606           52.2   \n",
      "13                                           20160607           56.9   \n",
      "14                                           20160608           54.2   \n",
      "15                                           20160609           49.4   \n",
      "16                                           20160610           49.5   \n",
      "17                                           20160611           54.0   \n",
      "18                                           20160612           55.4   \n",
      "19                                           20160613           58.3   \n",
      "20                                           20160614           59.7   \n",
      "21                                           20160615           63.4   \n",
      "22                                           20160616           57.8   \n",
      "23                                           20160617           60.4   \n",
      "24                                           20160618           57.3   \n",
      "25                                           20160619           56.3   \n",
      "26                                           20160620           59.3   \n",
      "27                                           20160621           62.6   \n",
      "28                                           20160622           61.7   \n",
      "29                                           20160623           60.9   \n",
      "30                                           20160624           61.1   \n",
      "31                                           20160625           65.7   \n",
      "32                                           20160626           69.6   \n",
      "33                                           20160627           60.7   \n",
      "34                                           20160628           65.4   \n",
      "35                                           20160629           65.8   \n",
      "36                                           20160630           65.7   \n",
      "\n",
      "    max) for Kumpula  Helsinki  \n",
      "0                NaN       NaN  \n",
      "1                NaN       NaN  \n",
      "2                NaN       NaN  \n",
      "3                NaN       NaN  \n",
      "4                NaN       NaN  \n",
      "5                NaN       NaN  \n",
      "6                MAX       MIN  \n",
      "7               73.6      54.7  \n",
      "8               80.8      55.0  \n",
      "9               77.9      55.6  \n",
      "10              70.9      47.3  \n",
      "11              58.3      43.2  \n",
      "12              59.7      42.8  \n",
      "13              65.1      45.9  \n",
      "14              60.4      47.5  \n",
      "15              54.1      45.7  \n",
      "16              55.9      43.0  \n",
      "17              62.1      41.7  \n",
      "18              64.2      46.0  \n",
      "19              68.2      47.3  \n",
      "20              67.8      47.8  \n",
      "21              70.3      49.3  \n",
      "22              67.5      55.6  \n",
      "23              70.7      55.9  \n",
      "24              62.8      54.0  \n",
      "25              59.2      54.1  \n",
      "26              69.1      52.2  \n",
      "27              71.4      50.4  \n",
      "28              70.2      55.4  \n",
      "29              67.1      54.9  \n",
      "30              68.9      56.7  \n",
      "31              75.4      57.9  \n",
      "32              77.7      60.3  \n",
      "33              70.0      57.6  \n",
      "34              73.0      55.8  \n",
      "35              73.2      59.7  \n",
      "36              72.7      59.2  \n"
     ]
    }
   ],
   "source": [
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks OK, but there are some strange values present such as `NaN`, and the first lines of the dataframe look a bit weird.. \n",
    "\n",
    "`NaN` stands for \"not a number\", and might indicate some problem with reading in the contents of the file. Plus, we expected about 30 lines of data, but the index values go up to 36 when we print the contents of the `dataFrame` variable. Looks like we need to investigate this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, there are some metadata at the top of the file giving basic information about its contents and source. This isn't data we want to process, so we need to skip over that part of the file when we load it.\n",
    "\n",
    "Here are the 8 first rows of data in the text file (note that the 8th row is blank):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "# Data processing: Extracted temperatures from raw data file, converted to\n",
    "#                  comma-separated format\n",
    "#\n",
    "# David Whipp - 02.10.2017\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, that's easy to do in Pandas, we just **need to add the `skiprows` parameter when we read the file, listing the number of rows to skip (8 in this case).**\n",
    "\n",
    "Let's try reading the datafile again using Pandas, and this time defining the `skiprows` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv('Kumpula-June-2016-w-metadata.txt', skiprows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the rows and see what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN\n",
      "0   20160601  65.5  73.6  54.7\n",
      "1   20160602  65.8  80.8  55.0\n",
      "2   20160603  68.4  77.9  55.6\n",
      "3   20160604  57.5  70.9  47.3\n",
      "4   20160605  51.4  58.3  43.2\n",
      "5   20160606  52.2  59.7  42.8\n",
      "6   20160607  56.9  65.1  45.9\n",
      "7   20160608  54.2  60.4  47.5\n",
      "8   20160609  49.4  54.1  45.7\n",
      "9   20160610  49.5  55.9  43.0\n",
      "10  20160611  54.0  62.1  41.7\n",
      "11  20160612  55.4  64.2  46.0\n",
      "12  20160613  58.3  68.2  47.3\n",
      "13  20160614  59.7  67.8  47.8\n",
      "14  20160615  63.4  70.3  49.3\n",
      "15  20160616  57.8  67.5  55.6\n",
      "16  20160617  60.4  70.7  55.9\n",
      "17  20160618  57.3  62.8  54.0\n",
      "18  20160619  56.3  59.2  54.1\n",
      "19  20160620  59.3  69.1  52.2\n",
      "20  20160621  62.6  71.4  50.4\n",
      "21  20160622  61.7  70.2  55.4\n",
      "22  20160623  60.9  67.1  54.9\n",
      "23  20160624  61.1  68.9  56.7\n",
      "24  20160625  65.7  75.4  57.9\n",
      "25  20160626  69.6  77.7  60.3\n",
      "26  20160627  60.7  70.0  57.6\n",
      "27  20160628  65.4  73.0  55.8\n",
      "28  20160629  65.8  73.2  59.7\n",
      "29  20160630  65.7  72.7  59.2\n"
     ]
    }
   ],
   "source": [
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks more like it.\n",
    "\n",
    "So, what happened? Why did the dataframe look weird before we skipped the first rows? \n",
    "\n",
    "Well, the file data was read into a Pandas **DataFrame**, which is  a two-dimensional structure used for storing table-like data. A pandas dataframe contains a collection of columns, which can all be a different value type (string, float, int, boolean, etc.).\n",
    "\n",
    "In our first attempt to read data from the text file, the first rows containing metadata did not belong to the actual data array, and that's why the output looked weird. \n",
    "\n",
    "**By default, the `read_csv`-function infers column names from the first line of the file.** For other options, see parameter `header` in the [read_csv documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "**What would happen if we skipped 9 rows? (try it out!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, one of the neat things in Pandas is that that DataFrames have labelled axes (rows and columns).  For our example, we have the rows labeled with an index value (`0` to `29`), and columns labelled `YEARMODA`, `TEMP`, `MAX`, and `MIN`. This is nice because we can easily use these labels to divide up our data and make interacting with it easier as you'll see later in the lesson.\n",
    "\n",
    "The example above, when trying to read a datafile with some header text (the metadata in this case), is *very* common. Reading data into Pandas is pretty easy, but **it helps to have a sense of what the datafile looks like before you try to read it**. \n",
    "\n",
    "After reading in the data, it is always good to check that everything went well (for example as we did with the print-statement above). The challenge can also be that large datafiles might not nicely print on screen using the `print()`-function so it might be better to look at only the top 5-10 lines of the file rather than loading the entire thing. \n",
    "\n",
    "**We can  use `pandas.DataFrame.head` -function to quickly check the contents of the dataframe.** This function returns the first n rows for the dataframe. By default, it gives 5 first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160601</td>\n",
       "      <td>65.5</td>\n",
       "      <td>73.6</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160602</td>\n",
       "      <td>65.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160603</td>\n",
       "      <td>68.4</td>\n",
       "      <td>77.9</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160604</td>\n",
       "      <td>57.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160605</td>\n",
       "      <td>51.4</td>\n",
       "      <td>58.3</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMODA  TEMP   MAX   MIN\n",
       "0  20160601  65.5  73.6  54.7\n",
       "1  20160602  65.8  80.8  55.0\n",
       "2  20160603  68.4  77.9  55.6\n",
       "3  20160604  57.5  70.9  47.3\n",
       "4  20160605  51.4  58.3  43.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move on to exploring our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our dataset\n",
    "\n",
    "We now have some basic Python skills and the ability to read in data from a file for processing. A normal first step when you load new data is to explore the dataset a bit to understand how the data is structured, and what kind of values are stored in there.\n",
    "\n",
    "**Let's start by looking at the different columns we have in our DataFrame.** We can find this in the `columns`  attribute that is part of the DataFrame object (columns is an in-built attribute in the DataFrame data type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YEARMODA', 'TEMP', 'MAX', 'MIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Print columns\n",
    "print(dataFrame.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the names of the different columns in the datafile, as one might expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also find information about the rows in the datafile using the ``index`` attribute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=30, step=1)\n"
     ]
    }
   ],
   "source": [
    "#Print index\n",
    "print(dataFrame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see how the data is indexed, starting at 0, ending at 30, and with an increment of 1 between each value. This is basically the same way in which Python lists are indexed, but it suggests that maybe there are other ways to identify the rows in data using Pandas.\n",
    "   \n",
    "Again, we'll see a bit more about this later.\n",
    "\n",
    "For now, it is also useful to point out that **if you want to just know how many rows you have, you can use the ``len()`` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Print number of rows using len()-function\n",
    "# print(len(dataFrame.index))\n",
    "print(len(dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also get a quick sense of the size of the dataset using the ``shape`` attribute.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print dataframe shape\n",
    "print(dataFrame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that our dataset has 30 rows, 4 columns, just as we saw above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the types of data we have in our DataFrame.\n",
    "**First, let's see what type of data the DataFrame is.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data type of the dataFrame variable\n",
    "type(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprises here, our Pandas DataFrame is a Pandas DataFrame ;)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We can also use IPython magic to figure out what kind of variable we have in memory. IPython magic command `%who` will display names of those variables that you have defined during this session. Magic command `%whose` prints out more information about these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable    Type         Data/Info\n",
      "----------------------------------\n",
      "dataFrame   DataFrame        YEARMODA  TEMP   MAX <...>0160630  65.7  72.7  59.2\n",
      "pd          module       <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "# Display variable names:\n",
    "#%who\n",
    "\n",
    "# Display variable name, type and info\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what about the data types of each column in our dataFrame? Finding the types of data in the columns of the DataFrame is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEARMODA      int64\n",
      "TEMP        float64\n",
      "MAX         float64\n",
      "MIN         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print data types\n",
    "print(dataFrame.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The ``dtypes`` attribute holds the data types for each column, nice.\n",
    "   Here we see that ``YEARMODA`` is an integer value (with 64-bit precision; int64), while the other values are all decimal values with 64-bit precision (float64)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also select a single column of the data using the column name:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65.5\n",
      "1     65.8\n",
      "2     68.4\n",
      "3     57.5\n",
      "4     51.4\n",
      "5     52.2\n",
      "6     56.9\n",
      "7     54.2\n",
      "8     49.4\n",
      "9     49.5\n",
      "10    54.0\n",
      "11    55.4\n",
      "12    58.3\n",
      "13    59.7\n",
      "14    63.4\n",
      "15    57.8\n",
      "16    60.4\n",
      "17    57.3\n",
      "18    56.3\n",
      "19    59.3\n",
      "20    62.6\n",
      "21    61.7\n",
      "22    60.9\n",
      "23    61.1\n",
      "24    65.7\n",
      "25    69.6\n",
      "26    60.7\n",
      "27    65.4\n",
      "28    65.8\n",
      "29    65.7\n",
      "Name: TEMP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Print out a single column\n",
    "print(dataFrame['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, printing out its values shows not only the values, but also their data type.\n",
    "What about the type of the column itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datatype of that column\n",
    "type(dataFrame['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So rather than seeing a DataFrame type or float64, a selected column from a DataFrame is called a *Series* in Pandas. Here, we will briefly see how you can create a Pandas Series from a Python list (and further convert it into a Pandas DataFrame..). \n",
    "\n",
    "If you have long lists of numbers, for instance, creating a Pandas Series will allow you to interact with these values more efficiently in terms of computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create Pandas Series from a list\n",
    "myList = [1, 2, 3, 4, 5, 6, 7.0]\n",
    "mySeries = pd.Series(myList)\n",
    "print(mySeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, ``myList`` is converted to a Pandas Series using the ``ps.Series()`` function. Also, note that Pandas is smart about the conversion, detecting a single floating point value (``7.0``) and assigning all values in the Series the data type float64.\n",
    "\n",
    "In turn, we could convert this series back into a pandas dataframe by initiating a new [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Check data type of the input\n",
    "print(type(mySeries))\n",
    "\n",
    "# Create a pandas dataframe\n",
    "myDataFrame = pd.DataFrame(mySeries)\n",
    "\n",
    "#Check the data type\n",
    "print(type(myDataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  1.0\n",
      "1  2.0\n",
      "2  3.0\n",
      "3  4.0\n",
      "4  5.0\n",
      "5  6.0\n",
      "6  7.0\n"
     ]
    }
   ],
   "source": [
    "print(myDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a pandas dataframe with one column of data, and an associated index. By default, the column name (label) has been set to '0'. We can still give our column a new name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number\n",
      "0     1.0\n",
      "1     2.0\n",
      "2     3.0\n",
      "3     4.0\n",
      "4     5.0\n",
      "5     6.0\n",
      "6     7.0\n"
     ]
    }
   ],
   "source": [
    "# Rename the first column\n",
    "myDataFrame.columns = [\"number\"]\n",
    "print(myDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with our original DataFrame `dataFrame` and columns stored in there.\n",
    "\n",
    "Just like DataFrames, Pandas Series have a set of attributes they know about themselves and methods they can use to make calculations using the Series data.\n",
    "\n",
    "Useful methods include `mean()`, `median()`, `min()`, `max()`, and `std()` (the standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.73"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mean value of a column\n",
    "dataFrame['TEMP'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't even need to store `dataFrame['TEMP']` as a separate series in order to find the mean value using the `mean()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful function to get an overview of the basic statistics for all attributes in your DataFrame is the ``describe()`` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>59.730000</td>\n",
       "      <td>67.940000</td>\n",
       "      <td>51.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.803408e+00</td>\n",
       "      <td>5.475472</td>\n",
       "      <td>6.651761</td>\n",
       "      <td>5.634484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016060e+07</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>41.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.016061e+07</td>\n",
       "      <td>56.450000</td>\n",
       "      <td>63.150000</td>\n",
       "      <td>47.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>60.050000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>54.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.016062e+07</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>72.375000</td>\n",
       "      <td>55.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.016063e+07</td>\n",
       "      <td>69.600000</td>\n",
       "      <td>80.800000</td>\n",
       "      <td>60.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEARMODA       TEMP        MAX        MIN\n",
       "count  3.000000e+01  30.000000  30.000000  30.000000\n",
       "mean   2.016062e+07  59.730000  67.940000  51.750000\n",
       "std    8.803408e+00   5.475472   6.651761   5.634484\n",
       "min    2.016060e+07  49.400000  54.100000  41.700000\n",
       "25%    2.016061e+07  56.450000  63.150000  47.300000\n",
       "50%    2.016062e+07  60.050000  69.000000  54.050000\n",
       "75%    2.016062e+07  64.900000  72.375000  55.750000\n",
       "max    2.016063e+07  69.600000  80.800000  60.300000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get descriptive statistics\n",
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are occasions where you'll need to convert data stored within a Series to another data type. \n",
    "\n",
    "If you're planning to print a large number of value to the screen, for instance, it might be helpful to have those values as character strings.\n",
    "\n",
    "Data type conversions is most easily done using the `astype()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65.5\n",
      "1     65.8\n",
      "2     68.4\n",
      "3     57.5\n",
      "4     51.4\n",
      "5     52.2\n",
      "6     56.9\n",
      "7     54.2\n",
      "8     49.4\n",
      "9     49.5\n",
      "10    54.0\n",
      "11    55.4\n",
      "12    58.3\n",
      "13    59.7\n",
      "14    63.4\n",
      "15    57.8\n",
      "16    60.4\n",
      "17    57.3\n",
      "18    56.3\n",
      "19    59.3\n",
      "20    62.6\n",
      "21    61.7\n",
      "22    60.9\n",
      "23    61.1\n",
      "24    65.7\n",
      "25    69.6\n",
      "26    60.7\n",
      "27    65.4\n",
      "28    65.8\n",
      "29    65.7\n",
      "Name: TEMP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convert temperature values to string\n",
    "print(dataFrame['TEMP'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the object data type indicates the temperature values are stored as character strings.\n",
    "   A more obvious case is converting to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     65\n",
      "1     65\n",
      "2     68\n",
      "3     57\n",
      "4     51\n",
      "5     52\n",
      "6     56\n",
      "7     54\n",
      "8     49\n",
      "9     49\n",
      "10    54\n",
      "11    55\n",
      "12    58\n",
      "13    59\n",
      "14    63\n",
      "15    57\n",
      "16    60\n",
      "17    57\n",
      "18    56\n",
      "19    59\n",
      "20    62\n",
      "21    61\n",
      "22    60\n",
      "23    61\n",
      "24    65\n",
      "25    69\n",
      "26    60\n",
      "27    65\n",
      "28    65\n",
      "29    65\n",
      "Name: TEMP, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Check the output\n",
    "print(dataFrame['TEMP'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can clearly see the temperature values are now whole numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "**Be careful with type conversions from floating point values to integers.** The conversion simply drops the stuff to the right of the decimal point, so all values are rounded down to the nearest whole number. For example, 99.99 will be rounded to 99 as an integer. This can be dangerous in some cases.\n",
    "\n",
    "Hence, it might be good to round the values before converting them to integers. Chaining the round and type conversion functions solves this issue as the `.round(0).astype(int)` command first rounds the values with zero decimals and then converts those values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated values:\n",
      "0    65\n",
      "1    65\n",
      "2    68\n",
      "3    57\n",
      "4    51\n",
      "Name: TEMP, dtype: int32\n",
      "\n",
      "\n",
      "Rounded values:\n",
      "0    66\n",
      "1    66\n",
      "2    68\n",
      "3    58\n",
      "4    51\n",
      "Name: TEMP, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Integer, truncated:\n",
    "print(\"Truncated values:\")\n",
    "print(dataFrame['TEMP'].astype(int).head())\n",
    "\n",
    "# Add empty line:\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Rounded values:\")\n",
    "#Integer, rounded:\n",
    "print(dataFrame['TEMP'].round(0).astype(int).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Next, we will have a look at [basic operations for data analysis in Pandas](processing-data-with-pandas.ipynb)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
